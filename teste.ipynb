{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test  samples\n",
      "Generation 1\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "Accuracy: 22.059999406337738\n",
      "The best accuracy so far 22.059999406337738%\n",
      "Generation 2\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "Accuracy: 25.859999656677246\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets.mnist import load_data\n",
    "from keras import backend as k\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from numpy.random import randint\n",
    "from random import choice\n",
    "from numpy.random import uniform\n",
    "\n",
    "\n",
    "def mnist(show_examples=False):\n",
    "    i_r, i_c, n_c = 28, 28, 10  # Image row, columns and class number \n",
    "    (x_tr, y_tr), (x_te, y_te) = load_data()  # Load mnist data\n",
    "    if k.image_data_format() == 'channels_first':\n",
    "        x_tr = x_tr.reshape(x_tr.shape[0], 1, i_r, i_c)\n",
    "        x_te = x_te.reshape(x_te.shape[0], 1, i_r, i_c)\n",
    "        i_sh = (1, i_r, i_c)\n",
    "    else:\n",
    "        x_tr = x_tr.reshape(x_tr.shape[0], i_r, i_c, 1)\n",
    "        x_te = x_te.reshape(x_te.shape[0], i_r, i_c, 1)\n",
    "        i_sh = (i_r, i_c, 1)\n",
    "    x_tr = x_tr.astype('float32')\n",
    "    x_te = x_te.astype('float32')\n",
    "    y_tr = to_categorical(y_tr, n_c)\n",
    "    y_te = to_categorical(y_te, n_c)\n",
    "    x_tr /= 255  # Normalize training images\n",
    "    x_te /= 255  # Normalize test     images\n",
    "    if show_examples:\n",
    "        print('X_tr:', x_tr.shape)\n",
    "        print(x_tr.shape[0], 'train samples')\n",
    "        print(x_te.shape[0], 'test  samples')\n",
    "    return x_tr, x_te, y_tr, y_te, i_sh\n",
    "\n",
    "\n",
    "class Net:\n",
    "    def __init__(self):\n",
    "        self.ep = randint(1, 3)               # epoch\n",
    "        self.f1 = randint(30, 34)             # filter size 1\n",
    "        self.f2 = randint(62, 66)             # filter size 2\n",
    "        self.u1 = randint(126, 130)           # unit\n",
    "        self.k1 = choice([(3, 3), (5, 5)])    # kernel size 1\n",
    "        self.k2 = choice([(3, 3), (5, 5)])    # kernel size 2\n",
    "        self.d1 = choice([0.25, 0.5])         #  dropout 1\n",
    "        self.d2 = choice([0.25, 0.5])         #  dropout 2\n",
    "        self.a1 = 'relu'                      # activation 1\n",
    "        self.a2 = 'relu'                      # activation 2\n",
    "        self.a3 = 'relu'                      # activation 3\n",
    "        self.a4 = 'softmax'                   # activation 4\n",
    "        self.lf = 'categorical_crossentropy'  # loss function\n",
    "        self.op = 'adadelta'                  # optimization\n",
    "        self.ac = 0                           # accuracy\n",
    "\n",
    "    def init_params(self):\n",
    "        params = {'epochs': self.ep,\n",
    "                  'filter1': self.f1,\n",
    "                  'kernel1': self.k1,\n",
    "                  'activation1': self.a1,\n",
    "                  'filter2': self.f2,\n",
    "                  'kernel2': self.k2,\n",
    "                  'activation2': self.a2,\n",
    "                  'pool_size': (2, 2),\n",
    "                  'dropout1': self.d1,\n",
    "                  'unit1': self.u1,\n",
    "                  'activation3': self.a3,\n",
    "                  'dropout2': self.d2,\n",
    "                  'activation4': self.a4,\n",
    "                  'loss': self.lf,\n",
    "                  'optimizer': self.op}\n",
    "        return params\n",
    "\n",
    "\n",
    "def init_net(p):\n",
    "    return [Net() for _ in range(p)]\n",
    "\n",
    "\n",
    "def fitness(n, n_c, i_shape, x, y, b, x_test, y_test):\n",
    "    for cnt, i in enumerate(n):\n",
    "        p = i.init_params()\n",
    "        ep = p['epochs']\n",
    "        f1 = p['filter1']\n",
    "        f2 = p['filter2']\n",
    "        k1 = p['kernel1']\n",
    "        k2 = p['kernel2']\n",
    "        d1 = p['dropout1']\n",
    "        d2 = p['dropout2']\n",
    "        ps = p['pool_size']\n",
    "        u1 = p['unit1']\n",
    "        a1 = p['activation1']\n",
    "        a2 = p['activation2']\n",
    "        a3 = p['activation3']\n",
    "        a4 = p['activation4']\n",
    "        lf = p['loss']\n",
    "        op = p['optimizer']\n",
    "\n",
    "        try:                                # Parameter name    # Suggested value\n",
    "            m = net_model(ep=ep,            # epoch number             12\n",
    "                          f1=f1,            # filter size 1            32\n",
    "                          f2=f2,            # filter size 2            64\n",
    "                          k1=k1,            # kernel 1               (3, 3)\n",
    "                          k2=k2,            # kernel 2               (3, 3)\n",
    "                          a1=a1,            # activation 1           'relu'\n",
    "                          a2=a2,            # activation 2           'relu'\n",
    "                          a3=a3,            # activation 3           'relu'\n",
    "                          a4=a4,            # activation 4           'softmax'\n",
    "                          d1=d1,            # dropout 1                0.25\n",
    "                          d2=d2,            # dropout 2                0.5\n",
    "                          u1=u1,            # neuron number            128\n",
    "                          ps=ps,            # pool size               (2, 2)\n",
    "                          op=op,            # optimizer               'adadelta'\n",
    "                          lf=lf,            # loss function           'categorical crossentropy'\n",
    "                          n_c=n_c,          # number of channel\n",
    "                          i_shape=i_shape,  # input shape\n",
    "                          x=x,              # train data\n",
    "                          y=y,              # train label\n",
    "                          b=b,              # bias value\n",
    "                          x_test=x_test,    # test data\n",
    "                          y_test=y_test)    # test label\n",
    "\n",
    "            # # Current best: 99.15%\n",
    "\n",
    "            s = m.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "            i.ac = s[1]\n",
    "            print('Accuracy: {}'.format(i.ac * 100))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return n\n",
    "\n",
    "\n",
    "def net_model(ep, f1, f2, k1, k2, a1, a2, a3, a4, d1, d2, u1, ps, op, lf, n_c, i_shape, x, y, b, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(layer=Conv2D(filters=f1, kernel_size=k1, activation=a1, input_shape=i_shape))\n",
    "    model.add(layer=Conv2D(filters=f2, kernel_size=k2, activation=a2))\n",
    "    model.add(layer=MaxPooling2D(pool_size=ps))\n",
    "    model.add(layer=Dropout(rate=d1))\n",
    "    model.add(layer=Flatten())\n",
    "    model.add(layer=Dense(units=u1, activation=a3))\n",
    "    model.add(layer=Dropout(rate=d2))\n",
    "    model.add(layer=Dense(units=n_c, activation=a4))\n",
    "    plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    model.compile(optimizer=op, loss=lf, metrics=['accuracy'])\n",
    "    model.fit(x=x, y=y, batch_size=b, epochs=ep, verbose=0, validation_data=(x_test, y_test))\n",
    "    return model\n",
    "\n",
    "\n",
    "def selection(n):\n",
    "    n = sorted(n, key=lambda j: j.ac, reverse=True)\n",
    "    n = n[:int(len(n))]\n",
    "    return n\n",
    "\n",
    "\n",
    "def crossover(n):\n",
    "    offspring = []\n",
    "    p1 = choice(n)\n",
    "    p2 = choice(n)\n",
    "    c1 = Net()\n",
    "    c2 = Net()\n",
    "    c1.ep = int(p2.ep) + 2\n",
    "    c2.ep = int(p1.ep) + 2\n",
    "    offspring.append(c1)\n",
    "    offspring.append(c2)\n",
    "    n.extend(offspring)\n",
    "    return n\n",
    "\n",
    "\n",
    "def mutate(n):\n",
    "    for i in n:\n",
    "        if uniform(0, 1) <= 0.1:\n",
    "            i.ep += randint(0, 5)\n",
    "            i.u1 += randint(0, 5)\n",
    "    return n\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    P = 1  # Population\n",
    "    G = 100  # Generation\n",
    "    B = 128  # Batch size\n",
    "    C = 10  # Class number\n",
    "    T = 0.994  # Threshold\n",
    "    N = init_net(p=P)  # Create population number networks \n",
    "    X_tr, X_te, Y_tr, Y_te, I_sh = mnist(show_examples=True)\n",
    "    accuracy_list = []\n",
    "    for g in range(G):\n",
    "        print('Generation {}'.format(g + 1))\n",
    "        N = fitness(n=N,\n",
    "                    n_c=C,\n",
    "                    i_shape=I_sh,\n",
    "                    x=X_tr,\n",
    "                    y=Y_tr,\n",
    "                    b=B,\n",
    "                    x_test=X_te,\n",
    "                    y_test=Y_te)\n",
    "        N = selection(n=N)\n",
    "        N = crossover(n=N)\n",
    "        N = mutate(n=N)\n",
    "\n",
    "        for q in N:\n",
    "            accuracy_list.append(q.ac * 100)\n",
    "            if q.ac > T:\n",
    "                print('Threshold satisfied')\n",
    "                print(q.init_params())\n",
    "                print('Best accuracy: {}%'.format(q.ac * 100))\n",
    "                exit(code=0)\n",
    "\n",
    "        print(\"The best accuracy so far {}%\".format(max(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
