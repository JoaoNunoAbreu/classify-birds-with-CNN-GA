{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2872,
     "status": "ok",
     "timestamp": 1597829594816,
     "user": {
      "displayName": "HaYoung Chang",
      "photoUrl": "",
      "userId": "16445981192279789957"
     },
     "user_tz": -540
    },
    "id": "l1vOBPZy-cYo"
   },
   "outputs": [],
   "source": [
    "import keras,matplotlib, random, math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout,BatchNormalization,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35215 images belonging to 250 classes.\n",
      "Found 1250 images belonging to 250 classes.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K7So03as-hjc",
    "outputId": "6c420885-fe9a-4af9-9cbe-bc85783b8c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35215 images belonging to 250 classes.\n",
      "Found 1250 images belonging to 250 classes.\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "def binary_to_num(population):\n",
    "    # dropout rate1------------------------------------\n",
    "    dp_st = [str(i) for i in population[2][:7]]\n",
    "    dp_string = str(\"\".join(dp_st))\n",
    "    dp_num = int(dp_string, 2)\n",
    "    if dp_num > 80: dp_num = 80\n",
    "    dropout_rate = float(dp_num /100)\n",
    "    # dropout rate2------------------------------------\n",
    "    dp2_st = [str(i) for i in population[2][7:14]]\n",
    "    dp2_string = str(\"\".join(dp2_st))\n",
    "    dp2_num = int(dp2_string, 2)\n",
    "    if dp2_num > 80: dp2_num = 80\n",
    "    dropout2_rate = float(dp2_num /100)\n",
    "    # batch size---------------------------------------\n",
    "    batch_st = [str(i) for i in population[2][14:24]]\n",
    "    batch_string = str(\"\".join(batch_st))\n",
    "    batch_num = int(batch_string, 2)\n",
    "    if batch_num > 1000: batch_num = 1000\n",
    "    # learning rate-------------------------------------\n",
    "    lr_st = [str(i) for i in population[2][24:]]\n",
    "    lr_string = str(\"\".join(lr_st))\n",
    "    lr_num = int(lr_string, 2)\n",
    "    if lr_num > 100: lr_num = 100\n",
    "    elif lr_num == 0: lr_num = 1\n",
    "    lr_rate = float(lr_num / 1000)\n",
    "    return dropout_rate, dropout2_rate, batch_num, lr_rate\n",
    "\n",
    "def fitness(population):\n",
    "    high_accuracy = 0\n",
    "    # print(population[1])\n",
    "    dp1_num, dp2_num, batch_num, lr_rate = binary_to_num(population) \n",
    "    accuracy = cnn(dp1_num, dp2_num, batch_num, lr_rate) # 모델 돌려서 accuracy 값 저장\n",
    "    for i in range(len(accuracy)):\n",
    "      current_accuracy = round(accuracy[i],4)\n",
    "      population[1].append(current_accuracy)\n",
    "      if current_accuracy > high_accuracy: # 가장 높은 accuracy 값 저장\n",
    "        high_accuracy = current_accuracy\n",
    "    population= (high_accuracy, population[1], population[2])\n",
    "    return population\n",
    "\n",
    "\n",
    "def cnn(dp1_rate, dp2_rate, bat_size, lr_rate):\n",
    "  num_classes = 250 #맞출수 있는 레이블 개수\n",
    "  epochs = 10\n",
    "\n",
    "  # fashion mnist train 60000, test 1000개 있다\n",
    "  #Creating generator for Training DataSet\n",
    "  train_directory='dataset/train'\n",
    "  train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "  train_generator=train_datagen.flow_from_directory(train_directory,\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode='sparse',batch_size=256)\n",
    "  #Creating generator for Test DataSet\n",
    "  test_directory='dataset/test'\n",
    "  test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "  test_generator=test_datagen.flow_from_directory(test_directory,\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode='sparse',batch_size=256)\n",
    "\n",
    "  xf_train , yf_train  = next(train_generator)\n",
    "  xf_test , yf_test  = next(test_generator)\n",
    " \n",
    "  # one-hot encode the training and testing lables\n",
    "  yf_train = keras.utils.to_categorical(yf_train, num_classes)\n",
    "  yf_test = keras.utils.to_categorical(yf_test, num_classes)\n",
    "\n",
    "  #모델만들기 \n",
    "  from keras.applications import ResNet101V2\n",
    "  convlayer=ResNet101V2(input_shape=(224,224,3),weights='imagenet',include_top=False)\n",
    "    \n",
    "  model=Sequential()\n",
    "  model.add(convlayer) \n",
    "  model.add(Dropout(dp1_rate))\n",
    "  model.add(Flatten())\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(1024,kernel_initializer='he_uniform'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(dp2_rate))\n",
    "  model.add(Dense(250,activation='softmax'))\n",
    "\n",
    "  model.compile(loss = \"categorical_crossentropy\",\n",
    "              optimizer = keras.optimizers.Adadelta(learning_rate=lr_rate), #여기서 사용---------------\n",
    "              metrics = ['accuracy'])\n",
    "  \n",
    "  history = model.fit(xf_train,yf_train,\n",
    "                      batch_size = bat_size, #여기서 사용-----------------------\n",
    "                      epochs = epochs, \n",
    "                      verbose = 1,\n",
    "                      validation_data = (xf_test, yf_test))\n",
    "\n",
    "  new = list(history.history['val_accuracy'])\n",
    "  return(new)\n",
    "\n",
    "def selection(population, k):\n",
    "  tournament_pool = random.sample(population, k)\n",
    "  result = sorted(tournament_pool, key=lambda x:x[0], reverse=True)\n",
    "  return result[0]\n",
    "\n",
    "def one_point_crossover(p1, p2):\n",
    "  if np.array_equal(p1[2], p2[2]):\n",
    "    return (0, [], p1[2]), (0, [], p2[2])\n",
    "  else:\n",
    "    length = len(p1[2])\n",
    "    cut = random.randint(0, length-1)\n",
    "    o1 = p1[2][:cut]\n",
    "    o1.extend(p2[2][cut:])\n",
    "    o2 = p2[2][:cut]\n",
    "    o2.extend(p1[2][cut:])\n",
    "  return (0, [], o1), (0, [], o2)\n",
    "\n",
    "def two_point_crossover(p1, p2):\n",
    "  if np.array_equal(p1[2], p2[2]):\n",
    "    return (0, [], p1[2]), (0, [], p2[2])\n",
    "  else:\n",
    "    length = len(p1[2])\n",
    "    cut1 = random.randint(0, length-1)\n",
    "    cut2 = random.randint(0, length-1)\n",
    "    if cut1 < cut2:\n",
    "      cut1 = cut1\n",
    "      cut2 = cut2\n",
    "    elif cut1 > cut2:\n",
    "      save = cut1\n",
    "      cut1 = cut2\n",
    "      cut2 = save\n",
    "    else:\n",
    "      pass\n",
    "    first1, second1, third1 = p1[2][:cut1], p2[2][cut1:cut2], p1[2][cut2:]\n",
    "    first2, second2, third2 = p2[2][:cut1], p1[2][cut1:cut2], p2[2][cut2:]\n",
    "    o1 = first1 + second1 + third1\n",
    "    o2 = first2 + second2 + third2\n",
    "  return (0, [], o1), (0, [], o2)\n",
    "\n",
    "def uniform_crossover(p1, p2):\n",
    "  if np.array_equal(p1[2], p2[2]):\n",
    "    return (0, [], p1[2]), (0, [], p2[2])\n",
    "  else:\n",
    "    length = len(p1[2])\n",
    "    o1=[]\n",
    "    o2=[]\n",
    "    for i in range(length):\n",
    "      if random.random() < 0.5:\n",
    "        o1.append(p1[2][i])\n",
    "        o2.append(p2[2][i])\n",
    "      else:\n",
    "        o1.append(p2[2][i])\n",
    "        o2.append(p1[2][i])\n",
    "  return (0, [], o1), (0, [], o2)\n",
    "\n",
    "\n",
    "def bit_inversion_mutation(offspring, rate):\n",
    "  for i in range(len(offspring[2])):\n",
    "    if random.random() < rate:\n",
    "      if offspring[2][i] ==1:\n",
    "        offspring[2][i]=0\n",
    "      else:\n",
    "        offspring[2][i]=1\n",
    "  return offspring\n",
    "\n",
    "def scramble_mutation(offspring, rate):\n",
    "  if random.random() < rate:\n",
    "    length = len(offspring[2])\n",
    "    a = random.randint(0, length - 1)\n",
    "    b = random.randint(0, length - 1)\n",
    "    if a < b:\n",
    "      a = a\n",
    "      b = b\n",
    "    elif a > b:\n",
    "      save = a\n",
    "      a = b\n",
    "      b = save\n",
    "    else:\n",
    "        pass\n",
    "    first, second, third = offspring[2][:a], offspring[2][a:b], offspring[2][b:]\n",
    "    new_list = first + random.sample(second, len(second)) + third\n",
    "    offspring = (offspring[0], offspring[1], new_list)\n",
    "  return offspring\n",
    "\n",
    "def inversion_mutation(offspring, rate):\n",
    "  if random.random() < rate:\n",
    "    length = len(offspring[2])\n",
    "    a = random.randint(0, length - 1)\n",
    "    b = random.randint(0, length - 1)\n",
    "    if a < b:\n",
    "      a = a\n",
    "      b = b\n",
    "    elif a > b:\n",
    "      save = a\n",
    "      a = b\n",
    "      b = save\n",
    "    else:\n",
    "        pass\n",
    "    first, second, third = offspring[2][:a], offspring[2][a:b], offspring[2][b:]\n",
    "    new_list = first + second[::-1] + third\n",
    "    offspring = (offspring[0], offspring[1], new_list)\n",
    "  return offspring\n",
    "\n",
    "\n",
    "def ga(pop, gen):\n",
    "    population = []\n",
    "    for i in range(pop):\n",
    "        randomBinaryNumbers = np.random.randint(2, size=31) # 24bit\n",
    "        accuracy_list =[] # validation accuracy 저장할 리스트\n",
    "        binary_list = (0, accuracy_list, list(randomBinaryNumbers)) #list로 변환\n",
    "        fit = fitness(binary_list) # 각 chromosome조합으로 얻은 accuracy\n",
    "        population.append(fit)\n",
    "\n",
    "    for g in range(gen):\n",
    "      offspring =[]\n",
    "      while len(offspring) < pop:\n",
    "        parent1 = selection(population, 3)\n",
    "        parent2 = selection(population, 3)\n",
    "\n",
    "        # offspring1, offspring2 = one_point_crossover(parent1, parent2) # 잘못걸리면..5시간\n",
    "        offspring1, offspring2 = two_point_crossover(parent1, parent2) #시간이 좀더 빠름 길면 3시간 평균 2시간\n",
    "        # offspring1, offspring2 = uniform_crossover(parent1, parent2) #결과는 제일 좋으나..3시간에서 6시간도 걸린다..평균 4-5시간 \n",
    "\n",
    "        #3개의 crossover의 기준으로 사용---------------------------------------\n",
    "        # offspring1 = bit_inversion_mutation(offspring1, 0.1) #result1_1 (파일 저장 이름)\n",
    "        # offspring2 = bit_inversion_mutation(offspring2, 0.1)\n",
    "\n",
    "        # offspring1 = bit_inversion_mutation(offspring1, 0.3) #result3_1\n",
    "        # offspring2 = bit_inversion_mutation(offspring2, 0.3)\n",
    "\n",
    "        # offspring1 = bit_inversion_mutation(offspring1, 0.6) #result6_1\n",
    "        # offspring2 = bit_inversion_mutation(offspring2, 0.6)\n",
    "\n",
    "        # two-points crossover를 중심으로 사용----------------------------------\n",
    "        # offspring1 = scramble_mutation(offspring1, 0.1) #scramble1_result1_1\n",
    "        # offspring2 = scramble_mutation(offspring2, 0.1)\n",
    "\n",
    "        # offspring1 = scramble_mutation(offspring1, 0.3) #scramble3_result1_1\n",
    "        # offspring2 = scramble_mutation(offspring2, 0.3)\n",
    "\n",
    "        # offspring1 = scramble_mutation(offspring1, 0.6) #scramble6_result1_1\n",
    "        # offspring2 = scramble_mutation(offspring2, 0.6)\n",
    "\n",
    "        # offspring1 = inversion_mutation(offspring1, 0.1) #inversion1_result1_1\n",
    "        # offspring2 = inversion_mutation(offspring2, 0.1)\n",
    "\n",
    "        # offspring1 = inversion_mutation(offspring1, 0.3) #inversion3_result1_1\n",
    "        # offspring2 = inversion_mutation(offspring2, 0.3)\n",
    "\n",
    "        offspring1 = inversion_mutation(offspring1, 0.6) #inversion6_result1_1\n",
    "        offspring2 = inversion_mutation(offspring2, 0.6)\n",
    "\n",
    "        offspring1 = fitness(offspring1)\n",
    "        offspring2 = fitness(offspring2)\n",
    "\n",
    "        offspring.append(offspring1)\n",
    "        offspring.append(offspring2)\n",
    "      pool = population\n",
    "      pool.extend(offspring)\n",
    "      pool = sorted(pool, key = lambda x: x[0], reverse=True)\n",
    "      population = pool[:pop]\n",
    "    print(\"final population \", population)\n",
    "\n",
    "    final=[]\n",
    "    for j in range(pop):\n",
    "      dp_st = [str(i) for i in population[j][2][:7]]\n",
    "      dp_string = str(\"\".join(dp_st))\n",
    "      dp_num = int(dp_string, 2)\n",
    "      if dp_num > 80: dp_num = 80\n",
    "      dropout_rate = float(dp_num /100)\n",
    "      # dropout rate2------------------------------------\n",
    "      dp2_st = [str(i) for i in population[j][2][7:14]]\n",
    "      dp2_string = str(\"\".join(dp2_st))\n",
    "      dp2_num = int(dp2_string, 2)\n",
    "      if dp2_num > 80: dp2_num = 80\n",
    "      dropout2_rate = float(dp2_num /100)\n",
    "      # batch size---------------------------------------\n",
    "      batch_st = [str(i) for i in population[j][2][14:24]]\n",
    "      batch_string = str(\"\".join(batch_st))\n",
    "      batch_num = int(batch_string, 2)\n",
    "      if batch_num > 1000: batch_num = 1000\n",
    "      # learning rate-------------------------------------\n",
    "      lr_st = [str(i) for i in population[j][2][24:]]\n",
    "      lr_string = str(\"\".join(lr_st))\n",
    "      lr_num = int(lr_string, 2)\n",
    "      if lr_num > 100: lr_num = 100\n",
    "      elif lr_num == 0: lr_num = 1\n",
    "      lr_rate = float(lr_num / 1000)\n",
    "      savee= (population[j][0], population[j][1], (dropout_rate, dropout2_rate, batch_num, lr_rate))\n",
    "      final.append(savee)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ga(10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM3PTdohAnsSaSVK1ZFaANw",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "cnn_ga_final_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
