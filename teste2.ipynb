{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boxed-permission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n",
      "X_tr: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test  samples\n",
      "Generation 1\n",
      "Accuracy: 21.01999968290329\n",
      "The best accuracy so far 21.01999968290329%\n",
      "Generation 2\n",
      "Accuracy: 32.1399986743927\n",
      "Accuracy: 52.66000032424927\n",
      "Accuracy: 55.46000003814697\n",
      "The best accuracy so far 55.46000003814697%\n",
      "Generation 3\n",
      "Accuracy: 70.46999931335449\n",
      "Accuracy: 56.620001792907715\n",
      "Accuracy: 22.110000252723694\n",
      "Accuracy: 52.95000076293945\n",
      "Accuracy: 52.869999408721924\n",
      "The best accuracy so far 70.46999931335449%\n",
      "Generation 4\n",
      "Accuracy: 68.16999912261963\n",
      "Accuracy: 76.34999752044678\n",
      "Accuracy: 69.88999843597412\n",
      "Accuracy: 52.81999707221985\n",
      "Accuracy: 29.109999537467957\n",
      "Accuracy: 63.80000114440918\n",
      "Accuracy: 50.62999725341797\n",
      "The best accuracy so far 76.34999752044678%\n",
      "Generation 5\n",
      "Accuracy: 78.64000201225281\n",
      "Accuracy: 79.43999767303467\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cb6fee4392ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    195\u001b[0m                     \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m                     \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_te\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m                     y_test=Y_te)\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrossover\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cb6fee4392ad>\u001b[0m in \u001b[0;36mfitness\u001b[1;34m(n, n_c, i_shape, x, y, b, x_test, y_test)\u001b[0m\n\u001b[0;32m    121\u001b[0m                           \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m              \u001b[1;31m# bias value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                           \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[1;31m# test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                           y_test=y_test)    # test label\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;31m# # Current best: 99.15%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cb6fee4392ad>\u001b[0m in \u001b[0;36mnet_model\u001b[1;34m(ep, f1, f2, k1, k2, a1, a2, a3, a4, d1, d2, u1, ps, op, lf, n_c, i_shape, x, y, b, x_test, y_test)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model_plot.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.datasets.mnist import load_data\n",
    "from keras import backend as k\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from numpy.random import randint\n",
    "from random import choice\n",
    "from numpy.random import uniform\n",
    "\n",
    "\n",
    "def mnist(show_examples=False):\n",
    "    i_r, i_c, n_c = 28, 28, 10  # Image row, columns and class number \n",
    "    (x_tr, y_tr), (x_te, y_te) = load_data()  # Load mnist data\n",
    "    if k.image_data_format() == 'channels_first':\n",
    "        x_tr = x_tr.reshape(x_tr.shape[0], 1, i_r, i_c)\n",
    "        x_te = x_te.reshape(x_te.shape[0], 1, i_r, i_c)\n",
    "        i_sh = (1, i_r, i_c)\n",
    "    else:\n",
    "        x_tr = x_tr.reshape(x_tr.shape[0], i_r, i_c, 1)\n",
    "        x_te = x_te.reshape(x_te.shape[0], i_r, i_c, 1)\n",
    "        i_sh = (i_r, i_c, 1)\n",
    "    x_tr = x_tr.astype('float32')\n",
    "    x_te = x_te.astype('float32')\n",
    "    x_tr /= 255  # Normalize training images\n",
    "    x_te /= 255  # Normalize test     images\n",
    "    print(x_tr.shape)\n",
    "    print(y_tr.shape)\n",
    "    print(x_te.shape)\n",
    "    print(y_te.shape)\n",
    "    if show_examples:\n",
    "        print('X_tr:', x_tr.shape)\n",
    "        print(x_tr.shape[0], 'train samples')\n",
    "        print(x_te.shape[0], 'test  samples')\n",
    "    return x_tr, x_te, y_tr, y_te, i_sh\n",
    "\n",
    "\n",
    "class Net:\n",
    "    def __init__(self):\n",
    "        self.ep = randint(1, 3)               # epoch\n",
    "        self.f1 = randint(30, 34)             # filter size 1\n",
    "        self.f2 = randint(62, 66)             # filter size 2\n",
    "        self.u1 = randint(126, 130)           # unit\n",
    "        self.k1 = choice([(3, 3), (5, 5)])    # kernel size 1\n",
    "        self.k2 = choice([(3, 3), (5, 5)])    # kernel size 2\n",
    "        self.d1 = choice([0.25, 0.5])         #  dropout 1\n",
    "        self.d2 = choice([0.25, 0.5])         #  dropout 2\n",
    "        self.a1 = 'relu'                      # activation 1\n",
    "        self.a2 = 'relu'                      # activation 2\n",
    "        self.a3 = 'relu'                      # activation 3\n",
    "        self.a4 = 'softmax'                   # activation 4\n",
    "        self.lf = 'categorical_crossentropy'  # loss function\n",
    "        self.op = 'adadelta'                  # optimization\n",
    "        self.ac = 0                           # accuracy\n",
    "\n",
    "    def init_params(self):\n",
    "        params = {'epochs': self.ep,\n",
    "                  'filter1': self.f1,\n",
    "                  'kernel1': self.k1,\n",
    "                  'activation1': self.a1,\n",
    "                  'filter2': self.f2,\n",
    "                  'kernel2': self.k2,\n",
    "                  'activation2': self.a2,\n",
    "                  'pool_size': (2, 2),\n",
    "                  'dropout1': self.d1,\n",
    "                  'unit1': self.u1,\n",
    "                  'activation3': self.a3,\n",
    "                  'dropout2': self.d2,\n",
    "                  'activation4': self.a4,\n",
    "                  'loss': self.lf,\n",
    "                  'optimizer': self.op}\n",
    "        return params\n",
    "\n",
    "\n",
    "def init_net(p):\n",
    "    return [Net() for _ in range(p)]\n",
    "\n",
    "\n",
    "def fitness(n, n_c, i_shape, x, y, b, x_test, y_test):\n",
    "    for cnt, i in enumerate(n):\n",
    "        p = i.init_params()\n",
    "        ep = p['epochs']\n",
    "        f1 = p['filter1']\n",
    "        f2 = p['filter2']\n",
    "        k1 = p['kernel1']\n",
    "        k2 = p['kernel2']\n",
    "        d1 = p['dropout1']\n",
    "        d2 = p['dropout2']\n",
    "        ps = p['pool_size']\n",
    "        u1 = p['unit1']\n",
    "        a1 = p['activation1']\n",
    "        a2 = p['activation2']\n",
    "        a3 = p['activation3']\n",
    "        a4 = p['activation4']\n",
    "        lf = p['loss']\n",
    "        op = p['optimizer']\n",
    "\n",
    "        try:                                # Parameter name    # Suggested value\n",
    "            m = net_model(ep=ep,            # epoch number             12\n",
    "                          f1=f1,            # filter size 1            32\n",
    "                          f2=f2,            # filter size 2            64\n",
    "                          k1=k1,            # kernel 1               (3, 3)\n",
    "                          k2=k2,            # kernel 2               (3, 3)\n",
    "                          a1=a1,            # activation 1           'relu'\n",
    "                          a2=a2,            # activation 2           'relu'\n",
    "                          a3=a3,            # activation 3           'relu'\n",
    "                          a4=a4,            # activation 4           'softmax'\n",
    "                          d1=d1,            # dropout 1                0.25\n",
    "                          d2=d2,            # dropout 2                0.5\n",
    "                          u1=u1,            # neuron number            128\n",
    "                          ps=ps,            # pool size               (2, 2)\n",
    "                          op=op,            # optimizer               'adadelta'\n",
    "                          lf=lf,            # loss function           'categorical crossentropy'\n",
    "                          n_c=n_c,          # number of channel\n",
    "                          i_shape=i_shape,  # input shape\n",
    "                          x=x,              # train data\n",
    "                          y=y,              # train label\n",
    "                          b=b,              # bias value\n",
    "                          x_test=x_test,    # test data\n",
    "                          y_test=y_test)    # test label\n",
    "\n",
    "            # # Current best: 99.15%\n",
    "\n",
    "            s = m.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "            i.ac = s[1]\n",
    "            print('Accuracy: {}'.format(i.ac * 100))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return n\n",
    "\n",
    "\n",
    "def net_model(ep, f1, f2, k1, k2, a1, a2, a3, a4, d1, d2, u1, ps, op, lf, n_c, i_shape, x, y, b, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(layer=Conv2D(filters=f1, kernel_size=k1, activation=a1, input_shape=i_shape))\n",
    "    model.add(layer=Conv2D(filters=f2, kernel_size=k2, activation=a2))\n",
    "    model.add(layer=MaxPooling2D(pool_size=ps))\n",
    "    model.add(layer=Dropout(rate=d1))\n",
    "    model.add(layer=Flatten())\n",
    "    model.add(layer=Dense(units=u1, activation=a3))\n",
    "    model.add(layer=Dropout(rate=d2))\n",
    "    model.add(layer=Dense(units=n_c, activation=a4))\n",
    "    plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    model.compile(optimizer=op, loss=lf, metrics=['accuracy'])\n",
    "    model.fit(x=x, y=y, batch_size=b, epochs=ep, verbose=0, validation_data=(x_test, y_test))\n",
    "    return model\n",
    "\n",
    "\n",
    "def selection(n):\n",
    "    n = sorted(n, key=lambda j: j.ac, reverse=True)\n",
    "    n = n[:int(len(n))]\n",
    "    return n\n",
    "\n",
    "\n",
    "def crossover(n):\n",
    "    offspring = []\n",
    "    p1 = choice(n)\n",
    "    p2 = choice(n)\n",
    "    c1 = Net()\n",
    "    c2 = Net()\n",
    "    c1.ep = int(p2.ep) + 2\n",
    "    c2.ep = int(p1.ep) + 2\n",
    "    offspring.append(c1)\n",
    "    offspring.append(c2)\n",
    "    n.extend(offspring)\n",
    "    return n\n",
    "\n",
    "\n",
    "def mutate(n):\n",
    "    for i in n:\n",
    "        if uniform(0, 1) <= 0.1:\n",
    "            i.ep += randint(0, 5)\n",
    "            i.u1 += randint(0, 5)\n",
    "    return n\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    P = 1  # Population\n",
    "    G = 100  # Generation\n",
    "    B = 128  # Batch size\n",
    "    C = 10  # Class number\n",
    "    T = 0.994  # Threshold\n",
    "    N = init_net(p=P)  # Create population number networks \n",
    "    X_tr, X_te, Y_tr, Y_te, I_sh = mnist(show_examples=True)\n",
    "    accuracy_list = []\n",
    "    for g in range(G):\n",
    "        print('Generation {}'.format(g + 1))\n",
    "        N = fitness(n=N,\n",
    "                    n_c=C,\n",
    "                    i_shape=I_sh,\n",
    "                    x=X_tr,\n",
    "                    y=Y_tr,\n",
    "                    b=B,\n",
    "                    x_test=X_te,\n",
    "                    y_test=Y_te)\n",
    "        N = selection(n=N)\n",
    "        N = crossover(n=N)\n",
    "        N = mutate(n=N)\n",
    "\n",
    "        for q in N:\n",
    "            accuracy_list.append(q.ac * 100)\n",
    "            if q.ac > T:\n",
    "                print('Threshold satisfied')\n",
    "                print(q.init_params())\n",
    "                print('Best accuracy: {}%'.format(q.ac * 100))\n",
    "                exit(code=0)\n",
    "\n",
    "        print(\"The best accuracy so far {}%\".format(max(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-pension",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
